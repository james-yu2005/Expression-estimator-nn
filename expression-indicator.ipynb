{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":39603,"sourceType":"datasetVersion","datasetId":31050}],"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport cv2\nimport matplotlib.pyplot as plt\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nimport torch.optim as optim\nfrom torch.utils.data import Dataset, DataLoader\nfrom torchvision import transforms\ndevice = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\nprint(f\"Using device: {device}\")","metadata":{"execution":{"iopub.status.busy":"2024-09-09T02:59:32.955131Z","iopub.execute_input":"2024-09-09T02:59:32.955529Z","iopub.status.idle":"2024-09-09T02:59:32.962261Z","shell.execute_reply.started":"2024-09-09T02:59:32.955491Z","shell.execute_reply":"2024-09-09T02:59:32.961270Z"},"trusted":true},"execution_count":14,"outputs":[{"name":"stdout","text":"Using device: cuda\n","output_type":"stream"}]},{"cell_type":"code","source":"emotion_map = ['Anger', 'Disgust', 'Fear', 'Happy', 'Sad', 'Surprise', 'Neutral']\ndf=pd.read_csv('/kaggle/input/facial-expression/fer2013.csv')","metadata":{"execution":{"iopub.status.busy":"2024-09-09T02:59:32.963899Z","iopub.execute_input":"2024-09-09T02:59:32.964198Z","iopub.status.idle":"2024-09-09T02:59:35.954301Z","shell.execute_reply.started":"2024-09-09T02:59:32.964166Z","shell.execute_reply":"2024-09-09T02:59:35.953485Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"code","source":"df.head(10)","metadata":{"execution":{"iopub.status.busy":"2024-09-09T02:59:35.955589Z","iopub.execute_input":"2024-09-09T02:59:35.955999Z","iopub.status.idle":"2024-09-09T02:59:35.967735Z","shell.execute_reply.started":"2024-09-09T02:59:35.955948Z","shell.execute_reply":"2024-09-09T02:59:35.966821Z"},"trusted":true},"execution_count":16,"outputs":[{"execution_count":16,"output_type":"execute_result","data":{"text/plain":"   emotion                                             pixels     Usage\n0        0  70 80 82 72 58 58 60 63 54 58 60 48 89 115 121...  Training\n1        0  151 150 147 155 148 133 111 140 170 174 182 15...  Training\n2        2  231 212 156 164 174 138 161 173 182 200 106 38...  Training\n3        4  24 32 36 30 32 23 19 20 30 41 21 22 32 34 21 1...  Training\n4        6  4 0 0 0 0 0 0 0 0 0 0 0 3 15 23 28 48 50 58 84...  Training\n5        2  55 55 55 55 55 54 60 68 54 85 151 163 170 179 ...  Training\n6        4  20 17 19 21 25 38 42 42 46 54 56 62 63 66 82 1...  Training\n7        3  77 78 79 79 78 75 60 55 47 48 58 73 77 79 57 5...  Training\n8        3  85 84 90 121 101 102 133 153 153 169 177 189 1...  Training\n9        2  255 254 255 254 254 179 122 107 95 124 149 150...  Training","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>emotion</th>\n      <th>pixels</th>\n      <th>Usage</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>70 80 82 72 58 58 60 63 54 58 60 48 89 115 121...</td>\n      <td>Training</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0</td>\n      <td>151 150 147 155 148 133 111 140 170 174 182 15...</td>\n      <td>Training</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2</td>\n      <td>231 212 156 164 174 138 161 173 182 200 106 38...</td>\n      <td>Training</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>4</td>\n      <td>24 32 36 30 32 23 19 20 30 41 21 22 32 34 21 1...</td>\n      <td>Training</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>6</td>\n      <td>4 0 0 0 0 0 0 0 0 0 0 0 3 15 23 28 48 50 58 84...</td>\n      <td>Training</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>2</td>\n      <td>55 55 55 55 55 54 60 68 54 85 151 163 170 179 ...</td>\n      <td>Training</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>4</td>\n      <td>20 17 19 21 25 38 42 42 46 54 56 62 63 66 82 1...</td>\n      <td>Training</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>3</td>\n      <td>77 78 79 79 78 75 60 55 47 48 58 73 77 79 57 5...</td>\n      <td>Training</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>3</td>\n      <td>85 84 90 121 101 102 133 153 153 169 177 189 1...</td>\n      <td>Training</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>2</td>\n      <td>255 254 255 254 254 179 122 107 95 124 149 150...</td>\n      <td>Training</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"m,n = df.shape\nprint(m,n)","metadata":{"execution":{"iopub.status.busy":"2024-09-09T02:59:35.969595Z","iopub.execute_input":"2024-09-09T02:59:35.969875Z","iopub.status.idle":"2024-09-09T02:59:35.981351Z","shell.execute_reply.started":"2024-09-09T02:59:35.969845Z","shell.execute_reply":"2024-09-09T02:59:35.980503Z"},"trusted":true},"execution_count":17,"outputs":[{"name":"stdout","text":"35887 3\n","output_type":"stream"}]},{"cell_type":"code","source":"# Process data from FER2013\ndef preprocess_data(data):\n    labels = data['emotion'].values\n    \n    # Takes string values and forms an array with float32 data points of size 48 by 48\n    images = data['pixels'].apply(lambda x: np.array(x.split(), dtype='float32').reshape(48, 48))\n    \n    # Stack images into a 3D array (num_samples, 48, 48) -> (35887, 48, 48)\n    images = np.stack(images.values)  \n    \n    # Add a channel dimension for grayscale -> (num_samples, channels, 48, 48) -> (35887, 1, 48, 48)\n    # Pytorch models expect in format of (batch_size, channels, height, width)\n    images = np.expand_dims(images, axis=1)  \n    \n    # Normalize pixel values to [0, 1]\n    images /= 255.0  \n    return images, labels\n\n# Split data into train and test datasets\ntrain_images, train_labels = preprocess_data(df[:30000])\ntest_images, test_labels = preprocess_data(df[30000:])","metadata":{"execution":{"iopub.status.busy":"2024-09-09T02:59:35.982591Z","iopub.execute_input":"2024-09-09T02:59:35.982979Z","iopub.status.idle":"2024-09-09T02:59:53.404388Z","shell.execute_reply.started":"2024-09-09T02:59:35.982937Z","shell.execute_reply":"2024-09-09T02:59:53.403578Z"},"trusted":true},"execution_count":18,"outputs":[]},{"cell_type":"code","source":"\n# # Number of images to display\n# num_images = 5\n# # Define the number of columns for the grid layout\n# num_cols = 3\n# # Calculate the number of rows needed\n# num_rows = (num_images + num_cols - 1) // num_cols  # Ceiling division\n\n# # Create a figure with subplots\n# fig, axes = plt.subplots(num_rows, num_cols, figsize=(num_cols * 4, num_rows * 3))\n\n# # Flatten the axes array for easier iteration\n# axes = axes.flatten()\n\n# for i in range(num_images):\n#     ex_emotion = emotion_map[labels[i]]  # Provides format of (1,48,48)\n#     ex_image = images[i].squeeze()  # Squeezes first dimension to become (48,48)\n\n#     # Displaying with pyplot from matplotlib (do not need to convert back into 0-255, can keep as 0-1)\n#     axes[i].imshow(ex_image, cmap='gray')\n#     axes[i].set_title(f'Emotion Label: {ex_emotion}')\n#     axes[i].axis('off')\n\n# # Turn off the axes for unused plots\n# for j in range(num_images, len(axes)):\n#     axes[j].axis('off')\n\n# plt.show()","metadata":{"execution":{"iopub.status.busy":"2024-09-09T02:59:53.405543Z","iopub.execute_input":"2024-09-09T02:59:53.405835Z","iopub.status.idle":"2024-09-09T02:59:55.528287Z","shell.execute_reply.started":"2024-09-09T02:59:53.405803Z","shell.execute_reply":"2024-09-09T02:59:55.526777Z"},"trusted":true},"execution_count":19,"outputs":[{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)","Cell \u001b[0;32mIn[19], line 19\u001b[0m\n\u001b[1;32m     16\u001b[0m ex_image \u001b[38;5;241m=\u001b[39m images[i]\u001b[38;5;241m.\u001b[39msqueeze()  \u001b[38;5;66;03m# Squeezes first dimension to become (48,48)\u001b[39;00m\n\u001b[1;32m     18\u001b[0m \u001b[38;5;66;03m# Displaying with pyplot from matplotlib (do not need to convert back into 0-255, can keep as 0-1)\u001b[39;00m\n\u001b[0;32m---> 19\u001b[0m \u001b[43maxes\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mimshow\u001b[49m\u001b[43m(\u001b[49m\u001b[43mex_image\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcmap\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mgray\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     20\u001b[0m axes[i]\u001b[38;5;241m.\u001b[39mset_title(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mEmotion Label: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mex_emotion\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     21\u001b[0m axes[i]\u001b[38;5;241m.\u001b[39maxis(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124moff\u001b[39m\u001b[38;5;124m'\u001b[39m)\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/matplotlib/__init__.py:1446\u001b[0m, in \u001b[0;36m_preprocess_data.<locals>.inner\u001b[0;34m(ax, data, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1443\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(func)\n\u001b[1;32m   1444\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21minner\u001b[39m(ax, \u001b[38;5;241m*\u001b[39margs, data\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m   1445\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m data \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m-> 1446\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43max\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43mmap\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43msanitize_sequence\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1448\u001b[0m     bound \u001b[38;5;241m=\u001b[39m new_sig\u001b[38;5;241m.\u001b[39mbind(ax, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m   1449\u001b[0m     auto_label \u001b[38;5;241m=\u001b[39m (bound\u001b[38;5;241m.\u001b[39marguments\u001b[38;5;241m.\u001b[39mget(label_namer)\n\u001b[1;32m   1450\u001b[0m                   \u001b[38;5;129;01mor\u001b[39;00m bound\u001b[38;5;241m.\u001b[39mkwargs\u001b[38;5;241m.\u001b[39mget(label_namer))\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/matplotlib/axes/_axes.py:5663\u001b[0m, in \u001b[0;36mAxes.imshow\u001b[0;34m(self, X, cmap, norm, aspect, interpolation, alpha, vmin, vmax, origin, extent, interpolation_stage, filternorm, filterrad, resample, url, **kwargs)\u001b[0m\n\u001b[1;32m   5655\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mset_aspect(aspect)\n\u001b[1;32m   5656\u001b[0m im \u001b[38;5;241m=\u001b[39m mimage\u001b[38;5;241m.\u001b[39mAxesImage(\u001b[38;5;28mself\u001b[39m, cmap\u001b[38;5;241m=\u001b[39mcmap, norm\u001b[38;5;241m=\u001b[39mnorm,\n\u001b[1;32m   5657\u001b[0m                       interpolation\u001b[38;5;241m=\u001b[39minterpolation, origin\u001b[38;5;241m=\u001b[39morigin,\n\u001b[1;32m   5658\u001b[0m                       extent\u001b[38;5;241m=\u001b[39mextent, filternorm\u001b[38;5;241m=\u001b[39mfilternorm,\n\u001b[1;32m   5659\u001b[0m                       filterrad\u001b[38;5;241m=\u001b[39mfilterrad, resample\u001b[38;5;241m=\u001b[39mresample,\n\u001b[1;32m   5660\u001b[0m                       interpolation_stage\u001b[38;5;241m=\u001b[39minterpolation_stage,\n\u001b[1;32m   5661\u001b[0m                       \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m-> 5663\u001b[0m \u001b[43mim\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mset_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   5664\u001b[0m im\u001b[38;5;241m.\u001b[39mset_alpha(alpha)\n\u001b[1;32m   5665\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m im\u001b[38;5;241m.\u001b[39mget_clip_path() \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   5666\u001b[0m     \u001b[38;5;66;03m# image does not already have clipping set, clip to axes patch\u001b[39;00m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/matplotlib/image.py:697\u001b[0m, in \u001b[0;36m_ImageBase.set_data\u001b[0;34m(self, A)\u001b[0m\n\u001b[1;32m    695\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(A, PIL\u001b[38;5;241m.\u001b[39mImage\u001b[38;5;241m.\u001b[39mImage):\n\u001b[1;32m    696\u001b[0m     A \u001b[38;5;241m=\u001b[39m pil_to_array(A)  \u001b[38;5;66;03m# Needed e.g. to apply png palette.\u001b[39;00m\n\u001b[0;32m--> 697\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_A \u001b[38;5;241m=\u001b[39m \u001b[43mcbook\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msafe_masked_invalid\u001b[49m\u001b[43m(\u001b[49m\u001b[43mA\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m    699\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_A\u001b[38;5;241m.\u001b[39mdtype \u001b[38;5;241m!=\u001b[39m np\u001b[38;5;241m.\u001b[39muint8 \u001b[38;5;129;01mand\u001b[39;00m\n\u001b[1;32m    700\u001b[0m         \u001b[38;5;129;01mnot\u001b[39;00m np\u001b[38;5;241m.\u001b[39mcan_cast(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_A\u001b[38;5;241m.\u001b[39mdtype, \u001b[38;5;28mfloat\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msame_kind\u001b[39m\u001b[38;5;124m\"\u001b[39m)):\n\u001b[1;32m    701\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mImage data of dtype \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m cannot be converted to \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    702\u001b[0m                     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfloat\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_A\u001b[38;5;241m.\u001b[39mdtype))\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/matplotlib/cbook/__init__.py:719\u001b[0m, in \u001b[0;36msafe_masked_invalid\u001b[0;34m(x, copy)\u001b[0m\n\u001b[1;32m    718\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21msafe_masked_invalid\u001b[39m(x, copy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[0;32m--> 719\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43marray\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msubok\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    720\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m x\u001b[38;5;241m.\u001b[39mdtype\u001b[38;5;241m.\u001b[39misnative:\n\u001b[1;32m    721\u001b[0m         \u001b[38;5;66;03m# If we have already made a copy, do the byteswap in place, else make a\u001b[39;00m\n\u001b[1;32m    722\u001b[0m         \u001b[38;5;66;03m# copy with the byte order swapped.\u001b[39;00m\n\u001b[1;32m    723\u001b[0m         x \u001b[38;5;241m=\u001b[39m x\u001b[38;5;241m.\u001b[39mbyteswap(inplace\u001b[38;5;241m=\u001b[39mcopy)\u001b[38;5;241m.\u001b[39mnewbyteorder(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mN\u001b[39m\u001b[38;5;124m'\u001b[39m)  \u001b[38;5;66;03m# Swap to native order.\u001b[39;00m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/_tensor.py:1083\u001b[0m, in \u001b[0;36mTensor.__array__\u001b[0;34m(self, dtype)\u001b[0m\n\u001b[1;32m   1081\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(Tensor\u001b[38;5;241m.\u001b[39m__array__, (\u001b[38;5;28mself\u001b[39m,), \u001b[38;5;28mself\u001b[39m, dtype\u001b[38;5;241m=\u001b[39mdtype)\n\u001b[1;32m   1082\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m dtype \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m-> 1083\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnumpy\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1084\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1085\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnumpy()\u001b[38;5;241m.\u001b[39mastype(dtype, copy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n","\u001b[0;31mTypeError\u001b[0m: can't convert cuda:0 device type tensor to numpy. Use Tensor.cpu() to copy the tensor to host memory first."],"ename":"TypeError","evalue":"can't convert cuda:0 device type tensor to numpy. Use Tensor.cpu() to copy the tensor to host memory first.","output_type":"error"},{"output_type":"display_data","data":{"text/plain":"<Figure size 1200x600 with 6 Axes>","image/png":"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"},"metadata":{}}]},{"cell_type":"code","source":"# Define Dataset\nclass FER2013Dataset(Dataset):\n    def __init__(self, images, labels):\n        self.images = torch.tensor(images, dtype=torch.float32)  # Convert numpy array to torch tensor\n        self.labels = torch.tensor(labels, dtype=torch.long)    # Convert labels to long tensor for classification\n\n    def __len__(self):\n        return len(self.images)\n\n    def __getitem__(self, idx):\n        image = self.images[idx]\n        label = self.labels[idx]\n        return image, label\n    \nbatch_size = 64\nshuffle = True\n\n# Create dataset instance\ntrain_dataset = FER2013Dataset(train_images, train_labels)\ntest_dataset = FER2013Dataset(test_images, test_labels)\n\n# Create data loader\ntrain_dataloader = DataLoader(train_dataset, batch_size=batch_size, shuffle=shuffle)\ntest_dataloader = DataLoader(test_dataset, batch_size=batch_size, shuffle=shuffle)","metadata":{"execution":{"iopub.status.busy":"2024-09-09T03:00:10.047399Z","iopub.execute_input":"2024-09-09T03:00:10.047802Z","iopub.status.idle":"2024-09-09T03:00:10.152100Z","shell.execute_reply.started":"2024-09-09T03:00:10.047762Z","shell.execute_reply":"2024-09-09T03:00:10.151234Z"},"trusted":true},"execution_count":20,"outputs":[]},{"cell_type":"code","source":"# Define the model\nclass SimpleCNN(nn.Module):\n    def __init__(self):\n        super(SimpleCNN, self).__init__()\n        self.conv1 = nn.Conv2d(1, 32, kernel_size=3, stride=1, padding=1)\n        self.conv2 = nn.Conv2d(32, 64, kernel_size=3, stride=1, padding=1)\n        self.pool = nn.MaxPool2d(kernel_size=2, stride=2, padding=0)\n        self.fc1 = nn.Linear(64 * 12 * 12, 128)\n        self.fc2 = nn.Linear(128, 7)  # 7 emotions\n\n    def forward(self, x):\n        x = self.pool(F.relu(self.conv1(x)))\n        x = self.pool(F.relu(self.conv2(x)))\n        x = x.view(-1, 64 * 12 * 12)\n        x = F.relu(self.fc1(x))\n        x = self.fc2(x)\n        return x\n\nmodel = SimpleCNN().to(device)","metadata":{"execution":{"iopub.status.busy":"2024-09-09T03:00:11.940812Z","iopub.execute_input":"2024-09-09T03:00:11.941160Z","iopub.status.idle":"2024-09-09T03:00:11.960784Z","shell.execute_reply.started":"2024-09-09T03:00:11.941126Z","shell.execute_reply":"2024-09-09T03:00:11.959854Z"},"trusted":true},"execution_count":21,"outputs":[]},{"cell_type":"code","source":"num_epochs = 10\nlearning_rate = 0.001\n\ncriterion = nn.CrossEntropyLoss()\noptimizer = optim.Adam(model.parameters(), lr=learning_rate)\n\nfor epoch in range(num_epochs):\n    running_loss = 0.0\n    for i, (images,labels) in enumerate(dataloader):\n        images, labels = images.to(device), labels.to(device)  # Move data to GPU\n\n        optimizer.zero_grad()\n        outputs = model(images)\n        loss = criterion(outputs, labels)\n        loss.backward()\n        optimizer.step()\n\n        running_loss += loss.item()\n\n        if (i + 1) % 100 == 0:\n            print(f'Epoch [{epoch + 1}/{num_epochs}], Batch [{i + 1}/{len(dataloader)}], Loss: {running_loss / (i + 1):.4f}')\n    \n    print(f'Epoch [{epoch + 1}/{num_epochs}], Loss: {running_loss / len(dataloader):.4f}')\n\n# Save the model\ntorch.save(model.state_dict(), 'fer2013_model.pth')","metadata":{"execution":{"iopub.status.busy":"2024-09-09T03:00:13.344227Z","iopub.execute_input":"2024-09-09T03:00:13.344706Z","iopub.status.idle":"2024-09-09T03:00:37.030216Z","shell.execute_reply.started":"2024-09-09T03:00:13.344664Z","shell.execute_reply":"2024-09-09T03:00:37.029035Z"},"trusted":true},"execution_count":22,"outputs":[{"name":"stdout","text":"Epoch [1/10], Batch [100/561], Loss: 1.7890\nEpoch [1/10], Batch [200/561], Loss: 1.7415\nEpoch [1/10], Batch [300/561], Loss: 1.7064\nEpoch [1/10], Batch [400/561], Loss: 1.6762\nEpoch [1/10], Batch [500/561], Loss: 1.6527\nEpoch [1/10], Loss: 1.6387\nEpoch [2/10], Batch [100/561], Loss: 1.4895\nEpoch [2/10], Batch [200/561], Loss: 1.4720\nEpoch [2/10], Batch [300/561], Loss: 1.4616\nEpoch [2/10], Batch [400/561], Loss: 1.4511\nEpoch [2/10], Batch [500/561], Loss: 1.4392\nEpoch [2/10], Loss: 1.4332\nEpoch [3/10], Batch [100/561], Loss: 1.3298\nEpoch [3/10], Batch [200/561], Loss: 1.3320\nEpoch [3/10], Batch [300/561], Loss: 1.3263\nEpoch [3/10], Batch [400/561], Loss: 1.3241\nEpoch [3/10], Batch [500/561], Loss: 1.3151\nEpoch [3/10], Loss: 1.3148\nEpoch [4/10], Batch [100/561], Loss: 1.2245\nEpoch [4/10], Batch [200/561], Loss: 1.2242\nEpoch [4/10], Batch [300/561], Loss: 1.2290\nEpoch [4/10], Batch [400/561], Loss: 1.2344\nEpoch [4/10], Batch [500/561], Loss: 1.2285\nEpoch [4/10], Loss: 1.2268\nEpoch [5/10], Batch [100/561], Loss: 1.1442\nEpoch [5/10], Batch [200/561], Loss: 1.1478\nEpoch [5/10], Batch [300/561], Loss: 1.1539\nEpoch [5/10], Batch [400/561], Loss: 1.1501\nEpoch [5/10], Batch [500/561], Loss: 1.1546\nEpoch [5/10], Loss: 1.1537\nEpoch [6/10], Batch [100/561], Loss: 1.0655\nEpoch [6/10], Batch [200/561], Loss: 1.0700\nEpoch [6/10], Batch [300/561], Loss: 1.0768\nEpoch [6/10], Batch [400/561], Loss: 1.0777\nEpoch [6/10], Batch [500/561], Loss: 1.0806\nEpoch [6/10], Loss: 1.0804\nEpoch [7/10], Batch [100/561], Loss: 1.0090\nEpoch [7/10], Batch [200/561], Loss: 1.0035\nEpoch [7/10], Batch [300/561], Loss: 1.0034\nEpoch [7/10], Batch [400/561], Loss: 1.0102\nEpoch [7/10], Batch [500/561], Loss: 1.0156\nEpoch [7/10], Loss: 1.0149\nEpoch [8/10], Batch [100/561], Loss: 0.9121\nEpoch [8/10], Batch [200/561], Loss: 0.9214\nEpoch [8/10], Batch [300/561], Loss: 0.9375\nEpoch [8/10], Batch [400/561], Loss: 0.9388\nEpoch [8/10], Batch [500/561], Loss: 0.9465\nEpoch [8/10], Loss: 0.9470\nEpoch [9/10], Batch [100/561], Loss: 0.8542\nEpoch [9/10], Batch [200/561], Loss: 0.8664\nEpoch [9/10], Batch [300/561], Loss: 0.8656\nEpoch [9/10], Batch [400/561], Loss: 0.8676\nEpoch [9/10], Batch [500/561], Loss: 0.8722\nEpoch [9/10], Loss: 0.8778\nEpoch [10/10], Batch [100/561], Loss: 0.7753\nEpoch [10/10], Batch [200/561], Loss: 0.7878\nEpoch [10/10], Batch [300/561], Loss: 0.7892\nEpoch [10/10], Batch [400/561], Loss: 0.7935\nEpoch [10/10], Batch [500/561], Loss: 0.7981\nEpoch [10/10], Loss: 0.8066\n","output_type":"stream"}]},{"cell_type":"code","source":"from sklearn.metrics import classification_report, accuracy_score\n\n# Assuming you have a DataLoader for the test set\nmodel.eval()  # Set the model to evaluation mode\nall_labels = []\nall_preds = []\n\nwith torch.no_grad():\n    for images, labels in test_dataloader:\n        images, labels = images.to(device), labels.to(device)\n        outputs = model(images)\n        _, predicted = torch.max(outputs, 1)\n        all_labels.extend(labels.cpu().numpy())\n        all_preds.extend(predicted.cpu().numpy())\n\naccuracy = accuracy_score(all_labels, all_preds)\nprint(f'Accuracy: {accuracy:.4f}')\n\nprint(classification_report(all_labels, all_preds))","metadata":{"execution":{"iopub.status.busy":"2024-09-09T03:00:39.152585Z","iopub.execute_input":"2024-09-09T03:00:39.153301Z","iopub.status.idle":"2024-09-09T03:00:39.382529Z","shell.execute_reply.started":"2024-09-09T03:00:39.153264Z","shell.execute_reply":"2024-09-09T03:00:39.381399Z"},"trusted":true},"execution_count":23,"outputs":[{"name":"stdout","text":"Accuracy: 0.7551\n              precision    recall  f1-score   support\n\n           0       0.76      0.66      0.71       780\n           1       0.85      0.87      0.86        90\n           2       0.64      0.67      0.65       828\n           3       0.84      0.91      0.88      1468\n           4       0.65      0.66      0.66      1028\n           5       0.87      0.88      0.87       673\n           6       0.74      0.67      0.70      1020\n\n    accuracy                           0.76      5887\n   macro avg       0.76      0.76      0.76      5887\nweighted avg       0.75      0.76      0.75      5887\n\n","output_type":"stream"}]},{"cell_type":"code","source":"torch.save(model.state_dict(), 'fer2013_model.pth')","metadata":{"execution":{"iopub.status.busy":"2024-09-09T03:03:04.244382Z","iopub.execute_input":"2024-09-09T03:03:04.245012Z","iopub.status.idle":"2024-09-09T03:03:04.261277Z","shell.execute_reply.started":"2024-09-09T03:03:04.244972Z","shell.execute_reply":"2024-09-09T03:03:04.260103Z"},"trusted":true},"execution_count":25,"outputs":[]}]}